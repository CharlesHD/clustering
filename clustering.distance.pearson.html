<!DOCTYPE html PUBLIC ""
    "">
<html><head><meta charset="UTF-8" /><title>clustering.distance.pearson documentation</title><link rel="stylesheet" type="text/css" href="css/default.css" /><link rel="stylesheet" type="text/css" href="css/highlight.css" /><script type="text/javascript" src="js/highlight.min.js"></script><script type="text/javascript" src="js/jquery.min.js"></script><script type="text/javascript" src="js/page_effects.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body><div id="header"><h2>Generated by <a href="https://github.com/weavejester/codox">Codox</a></h2><h1><a href="index.html"><span class="project-title"><span class="project-name">Clustering</span> <span class="project-version">0.1.3</span></span></a></h1></div><div class="sidebar primary"><h3 class="no-link"><span class="inner">Project</span></h3><ul class="index-link"><li class="depth-1 "><a href="index.html"><div class="inner">Index</div></a></li></ul><h3 class="no-link"><span class="inner">Namespaces</span></h3><ul><li class="depth-1"><div class="no-link"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>clustering</span></div></div></li><li class="depth-2"><div class="no-link"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>average</span></div></div></li><li class="depth-3"><a href="clustering.average.simple.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>simple</span></div></a></li><li class="depth-2"><div class="no-link"><div class="inner"><span class="tree" style="top: -52px;"><span class="top" style="height: 61px;"></span><span class="bottom"></span></span><span>core</span></div></div></li><li class="depth-3 branch"><a href="clustering.core.hierarchical.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>hierarchical</span></div></a></li><li class="depth-3 branch"><a href="clustering.core.k-means.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>k-means</span></div></a></li><li class="depth-3"><a href="clustering.core.qt.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>qt</span></div></a></li><li class="depth-2"><div class="no-link"><div class="inner"><span class="tree" style="top: -114px;"><span class="top" style="height: 123px;"></span><span class="bottom"></span></span><span>data-viz</span></div></div></li><li class="depth-3 branch"><a href="clustering.data-viz.dendrogram.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>dendrogram</span></div></a></li><li class="depth-3"><a href="clustering.data-viz.image.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>image</span></div></a></li><li class="depth-2"><div class="no-link"><div class="inner"><span class="tree" style="top: -83px;"><span class="top" style="height: 92px;"></span><span class="bottom"></span></span><span>distance</span></div></div></li><li class="depth-3 branch"><a href="clustering.distance.common.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>common</span></div></a></li><li class="depth-3 branch"><a href="clustering.distance.euclidean.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>euclidean</span></div></a></li><li class="depth-3 branch"><a href="clustering.distance.levenshtein.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>levenshtein</span></div></a></li><li class="depth-3 branch current"><a href="clustering.distance.pearson.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>pearson</span></div></a></li><li class="depth-3"><a href="clustering.distance.spearman.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>spearman</span></div></a></li></ul></div><div class="sidebar secondary"><h3><a href="#top"><span class="inner">Public Vars</span></a></h3><ul><li class="depth-1"><a href="clustering.distance.pearson.html#var-correlation-coefficient"><div class="inner"><span>correlation-coefficient</span></div></a></li><li class="depth-1"><a href="clustering.distance.pearson.html#var-distance"><div class="inner"><span>distance</span></div></a></li><li class="depth-1"><a href="clustering.distance.pearson.html#var-squared-distance"><div class="inner"><span>squared-distance</span></div></a></li></ul></div><div class="namespace-docs" id="content"><h1 class="anchor" id="top">clustering.distance.pearson</h1><div class="doc"><pre class="plaintext">Pearson's correlation coefficient is the covariance of the two variables
divided by the product of their standard deviations, and is commonly
represented by the Greek letter ρ (rho).

Developed by Karl Pearson from a related idea introduced by Francis Galton
in the 1880s, this product-moment correlation coefficient is widely used in
the sciences as a measure of the degree of linear dependence between two
variables. Early work on the distribution of the sample correlation
coefficient was carried out by Anil Kumar Gain and R. A. Fisher from the
University of Cambridge.

See: <a href="https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient">https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient</a></pre></div><div class="public anchor" id="var-correlation-coefficient"><h3>correlation-coefficient</h3><div class="usage"><code>(correlation-coefficient xs ys)</code></div><div class="doc"><pre class="plaintext">Pearson product-moment correlation coefficient is a measure of the linear
correlation between two variables X and Y, giving a value between +1 and −1
inclusive, where 1 is total positive correlation, 0 is no correlation, and
−1 is total negative correlation.</pre></div><div class="src-link"><a href="http://github.com/rm-hull/clustering/blob/master/src/clustering/distance/pearson.clj#L44">view source</a></div></div><div class="public anchor" id="var-distance"><h3>distance</h3><div class="usage"><code>(distance xs ys)</code></div><div class="doc"><pre class="plaintext">Pearson's distance can be defined from their correlation coefficient as:

   d(X,Y) = 1 - ρ(X,Y)

Considering that the Pearson correlation coefficient falls between [−1, 1],
the Pearson distance lies in [0, 2].</pre></div><div class="src-link"><a href="http://github.com/rm-hull/clustering/blob/master/src/clustering/distance/pearson.clj#L60">view source</a></div></div><div class="public anchor" id="var-squared-distance"><h3>squared-distance</h3><div class="usage"><code>(squared-distance xs ys)</code></div><div class="doc"><pre class="plaintext">The Pearson Squared distance measures the similarity in shape between two
profiles, but can also capture inverse relationships.

While most combinations of clustering algorithm and distance metrics provide
meaningful results, there are a few combinations that are difficult to
interpret. In particular, combining K-Means clustering with the Pearson
Squared distance metric can lead to non-intuitive centroid plots since the
centroid represents the mean of the cluster and Pearson Squared can group
anti-correlated objects. In these cases, visually drilling into clusters to
see the individual members through the use of Cluster Plots produce better
results.</pre></div><div class="src-link"><a href="http://github.com/rm-hull/clustering/blob/master/src/clustering/distance/pearson.clj#L72">view source</a></div></div></div></body></html>